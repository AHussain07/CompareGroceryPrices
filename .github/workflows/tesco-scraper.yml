name: Tesco Price Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 12 * * 1'  # Mondays at 12 PM UTC (2 hours after Sainsbury's)

permissions:
  contents: write

jobs:
  scrape-tesco:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Increased for human-like delays
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget curl unzip xvfb
        sudo apt-get install -y libnss3-dev libatk-bridge2.0-0 libdrm2 libxkbcommon0 libgtk-3-0 libatspi2.0-0
        sudo apt-get install -y libasound2t64 libxrandr2 libpangocairo-1.0-0 libatk1.0-0 libcairo-gobject2 libgdk-pixbuf2.0-0
    
    - name: Install Chrome (stable version)
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # Get exact Chrome version
        CHROME_VERSION=$(google-chrome --version)
        echo "Installed Chrome version: $CHROME_VERSION"
    
    - name: Install Python dependencies
      run: |
        cd WebScrape
        pip install --upgrade pip
        pip install -r requirements.txt
        
        # Install additional dependencies for new scraper
        pip install undetected-chromedriver
        pip install psutil
        
        echo "Installed packages:"
        pip list | grep -E "(selenium|pandas|undetected|psutil|beautifulsoup|lxml|requests)"
    
    - name: Create public directory
      run: mkdir -p app/public
    
    - name: Run Tesco scraper (Human-like)
      timeout-minutes: 175
      run: |
        cd WebScrape
        echo "ðŸ¤– Starting Human-like Tesco scraper..."
        echo "ðŸ“‹ Mode: Sequential browsing with human behavior"
        echo "â±ï¸ Strategy: Realistic delays and navigation"
        echo "ðŸ”§ Driver: UC Chrome with minimal stealth"
        echo "ðŸ›¡ï¸ Anti-detection: Cookie handling, scrolling, breaks"
        echo "ðŸ• Started: $(date)"
        
        # Set display for virtual framebuffer
        export DISPLAY=:99
        
        # Start virtual display
        Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
        sleep 5
        
        # Run the new-tesco.py script
        echo "Executing: python new-tesco.py"
        timeout 10500 python new-tesco.py 2>&1 | tee tesco.log
        
        echo "Tesco scraper completed at: $(date)"
    
    - name: Check results and copy CSV
      id: results
      run: |
        cd WebScrape
        
        echo "Checking for output files..."
        ls -la *.csv 2>/dev/null || echo "No CSV files found"
        
        if [ -f "tesco.csv" ]; then
          echo "âœ… Found tesco.csv"
          
          # Copy to public directory
          cp tesco.csv ../app/public/
          echo "âœ… Copied to app/public/"
          
          # Get detailed stats
          total_lines=$(wc -l < tesco.csv)
          product_count=$((total_lines - 1))
          file_size=$(ls -lh tesco.csv | awk '{print $5}')
          
          echo "ðŸ“Š Results:"
          echo "- Products: $product_count"
          echo "- File size: $file_size"
          echo "- Total lines: $total_lines"
          
          # Check if we actually got products
          if [ $product_count -gt 100 ]; then  # Expect at least 100 products
            echo "success=true" >> $GITHUB_OUTPUT
            echo "product_count=$product_count" >> $GITHUB_OUTPUT
            
            # Show sample products
            echo ""
            echo "ðŸ“‹ Sample products (first 5):"
            head -6 tesco.csv | tail -5
            
            # Show category breakdown
            echo ""
            echo "ðŸ“Š Categories with products:"
            tail -n +2 tesco.csv | cut -d',' -f1 | sort | uniq -c | sort -nr | head -10
            
            # Show performance stats from log
            echo ""
            echo "ðŸ“Š Performance stats:"
            grep -E "Total unique products:|Total time:|Products per second:" tesco.log | tail -3
            
          else
            echo "âš ï¸ CSV file created but contains only $product_count products (expected more)"
            echo "success=partial" >> $GITHUB_OUTPUT
            echo "product_count=$product_count" >> $GITHUB_OUTPUT
          fi
          
        else
          echo "âŒ No tesco.csv found"
          echo ""
          echo "ðŸ“‹ Directory contents:"
          ls -la
          echo ""
          echo "ðŸ“‹ Last 100 lines of log:"
          tail -100 tesco.log 2>/dev/null || echo "No log file"
          
          echo "success=false" >> $GITHUB_OUTPUT
          echo "product_count=0" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload logs and backup
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: tesco-logs
        path: |
          WebScrape/tesco.log
          WebScrape/new-tesco.py
        retention-days: 7
        if-no-files-found: ignore
    
    - name: Commit changes if successful
      if: steps.results.outputs.success == 'true' && steps.results.outputs.product_count > 100
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions - Tesco"
        
        # Add CSV file
        git add -f app/public/tesco.csv
        
        if ! git diff --staged --quiet; then
          echo "ðŸ“ Committing changes..."
          
          git commit -m "ðŸ¤– Tesco price update (Human-like) - $(date -u '+%Y-%m-%d %H:%M UTC')

          Products: ${{ steps.results.outputs.product_count }}
          Store: Tesco
          Script: new-tesco.py (Human-like browsing)
          Processing: Sequential with realistic delays
          Categories: All 7 categories
          
          Features:
          - Human-like navigation and scrolling
          - Realistic delays between pages
          - Cookie handling and security block avoidance
          - Single browser session (more human-like)
          - Break patterns to avoid detection
          
          Anti-detection measures:
          - UC Chrome with minimal stealth
          - Real navigation using Next buttons
          - Human scrolling patterns
          - 20-40 second breaks between categories
          - 15-30 second breaks every 10 pages
          
          Auto-updated via GitHub Actions"
          
          git push origin HEAD:${{ github.ref_name }}
          echo "âœ… Changes pushed successfully"
        else
          echo "â„¹ï¸ No changes to commit"
        fi
    
    - name: Commit partial results if needed
      if: steps.results.outputs.success == 'partial' && steps.results.outputs.product_count > 50
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions - Tesco (Partial)"
        
        # Add CSV file
        git add -f app/public/tesco.csv
        
        if ! git diff --staged --quiet; then
          echo "ðŸ“ Committing partial results..."
          
          git commit -m "âš ï¸ Tesco partial update - $(date -u '+%Y-%m-%d %H:%M UTC')

          Products: ${{ steps.results.outputs.product_count }} (Partial results)
          Store: Tesco
          Script: new-tesco.py (Human-like browsing)
          Status: Partial success - may have been blocked
          
          Note: Scraper may have encountered security blocks
          Consider manual review of results
          
          Auto-updated via GitHub Actions"
          
          git push origin HEAD:${{ github.ref_name }}
          echo "âœ… Partial results pushed"
        fi
    
    - name: Summary
      if: always()
      run: |
        echo "## ðŸ¤– Tesco Human-like Scraper Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Run completed:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.results.outputs.success }}" == "true" ]; then
          echo "### âœ… Success" >> $GITHUB_STEP_SUMMARY
          echo "- **Products scraped:** ${{ steps.results.outputs.product_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Script:** new-tesco.py (Human-like browsing)" >> $GITHUB_STEP_SUMMARY
          echo "- **Processing:** Sequential with realistic delays" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** Data committed to repository" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ steps.results.outputs.success }}" == "partial" ]; then
          echo "### âš ï¸ Partial Success" >> $GITHUB_STEP_SUMMARY
          echo "- **Products scraped:** ${{ steps.results.outputs.product_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Script:** new-tesco.py (may have been blocked)" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** Partial results committed" >> $GITHUB_STEP_SUMMARY
          echo "- **Note:** May need manual review" >> $GITHUB_STEP_SUMMARY
        else
          echo "### âŒ Scraping Failed" >> $GITHUB_STEP_SUMMARY
          echo "- **Error:** Failed to generate usable CSV file" >> $GITHUB_STEP_SUMMARY
          echo "- **Script:** new-tesco.py attempted" >> $GITHUB_STEP_SUMMARY
          echo "- **Logs:** Check uploaded artifacts for details" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ¤– Human-like Scraping Details" >> $GITHUB_STEP_SUMMARY
        echo "- **Driver:** UC Chrome with minimal stealth" >> $GITHUB_STEP_SUMMARY
        echo "- **Navigation:** Real button clicks and human scrolling" >> $GITHUB_STEP_SUMMARY
        echo "- **Delays:** 3-7 seconds between pages" >> $GITHUB_STEP_SUMMARY
        echo "- **Breaks:** 20-40 seconds between categories" >> $GITHUB_STEP_SUMMARY
        echo "- **Session:** Single browser (more human-like)" >> $GITHUB_STEP_SUMMARY
        echo "- **Anti-detection:** Cookie handling, security block detection" >> $GITHUB_STEP_SUMMARY
        echo "- **Categories:** 7 main categories (sequential)" >> $GITHUB_STEP_SUMMARY
        echo "- **Timeout:** 3 hours total (for human-like delays)" >> $GITHUB_STEP_SUMMARY