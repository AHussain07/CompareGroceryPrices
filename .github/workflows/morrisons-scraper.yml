name: Morrisons Price Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 9 * * 1'  # Mondays at 9 AM UTC

permissions:
  contents: write

jobs:
  scrape-morrisons:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install system dependencies (robust)
      run: |
        sudo apt-get clean
        sudo apt-get update --fix-missing
        sudo apt-get install -y --fix-broken wget curl unzip xvfb
        sudo apt-get install -y --no-install-recommends libnss3-dev libatk-bridge2.0-0 libdrm2 libxkbcommon0 libgtk-3-0 libatspi2.0-0
    
    - name: Install Chrome
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        google-chrome --version
    
    - name: Install ChromeDriver
      run: |
        CHROME_VERSION=$(google-chrome --version | sed 's/Google Chrome //' | cut -d'.' -f1)
        echo "Chrome version: $CHROME_VERSION"
        
        if [ "$CHROME_VERSION" -ge "115" ]; then
          echo "Using new ChromeDriver API"
          LATEST_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_STABLE")
          echo "ChromeDriver version: $LATEST_VERSION"
          wget -O /tmp/chromedriver.zip "https://storage.googleapis.com/chrome-for-testing-public/$LATEST_VERSION/linux64/chromedriver-linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /tmp/
          sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
        else
          echo "Using legacy ChromeDriver API"
          DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}")
          echo "ChromeDriver version: $DRIVER_VERSION"
          wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /usr/local/bin/
        fi
        
        sudo chmod +x /usr/local/bin/chromedriver
        chromedriver --version
    
    - name: Install Python dependencies
      run: |
        cd WebScrape
        pip install --upgrade pip
        pip install -r requirements.txt
        echo "Installed packages:"
        pip list | grep -E "(selenium|beautifulsoup|pandas|undetected|lxml|requests)"
    
    - name: Simple Morrisons optimization
      run: |
        cd WebScrape
        echo "Checking Morrisons scraper..."
        
        # Simple sed-based optimization (safer than Python script)
        if [ -f "morrisons.py" ]; then
          # Backup original
          cp morrisons.py morrisons.py.backup
          
          # Reduce workers to 2 for GitHub Actions
          sed -i 's/max_workers=[0-9]*/max_workers=2/g' morrisons.py
          
          # Reduce max_scrolls slightly
          sed -i 's/max_scrolls=[0-9]*/max_scrolls=30/g' morrisons.py
          
          echo "✅ Morrisons scraper optimized:"
          echo "- Set max_workers=2"
          echo "- Set max_scrolls=30"
          echo "- Keeping all categories"
        else
          echo "❌ morrisons.py not found"
          exit 1
        fi
    
    - name: Create public directory
      run: mkdir -p app/public
    
    - name: Run Morrisons scraper
      timeout-minutes: 55
      run: |
        cd WebScrape
        echo "🛒 Starting Morrisons scraper..."
        echo "Time: $(date)"
        
        # Set display for virtual framebuffer
        export DISPLAY=:99
        
        # Start virtual display
        Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
        sleep 3
        
        # Run scraper with timeout and detailed logging
        echo "Running python morrisons.py..."
        timeout 3300 python morrisons.py 2>&1 | tee morrisons.log
        
        echo "Scraper completed at: $(date)"
    
    - name: Check results and copy CSV
      id: results
      run: |
        cd WebScrape
        
        echo "Checking for output files..."
        ls -la *.csv 2>/dev/null || echo "No CSV files found"
        
        if [ -f "morrisons.csv" ]; then
          echo "✅ Found morrisons.csv"
          
          # Copy to public directory
          cp morrisons.csv ../app/public/
          echo "✅ Copied to app/public/"
          
          # Get stats
          total_lines=$(wc -l < morrisons.csv)
          product_count=$((total_lines - 1))
          file_size=$(ls -lh morrisons.csv | awk '{print $5}')
          
          echo "📊 Results:"
          echo "- Products: $product_count"
          echo "- File size: $file_size"
          echo "- Total lines: $total_lines"
          
          # Set outputs
          echo "success=true" >> $GITHUB_OUTPUT
          echo "product_count=$product_count" >> $GITHUB_OUTPUT
          
          # Show first few lines
          echo ""
          echo "📋 First 3 products:"
          head -4 morrisons.csv | tail -3
          
        else
          echo "❌ No morrisons.csv found"
          echo ""
          echo "📋 Directory contents:"
          ls -la
          echo ""
          echo "📋 Last 20 lines of log:"
          tail -20 morrisons.log 2>/dev/null || echo "No log file"
          
          echo "success=false" >> $GITHUB_OUTPUT
          echo "product_count=0" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload logs and backup
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: morrisons-logs-and-backup
        path: |
          WebScrape/morrisons.log
          WebScrape/morrisons.py.backup
        retention-days: 7
        if-no-files-found: ignore
    
    - name: Commit changes if successful
      if: steps.results.outputs.success == 'true'
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions - Morrisons"
        
        # Add CSV file
        git add -f app/public/morrisons.csv
        
        if ! git diff --staged --quiet; then
          echo "📝 Committing changes..."
          
          git commit -m "🛒 Morrisons price update - $(date -u '+%Y-%m-%d %H:%M UTC')

          Products: ${{ steps.results.outputs.product_count }}
          Store: Morrisons (all categories)
          
          Auto-updated via GitHub Actions"
          
          git push origin HEAD:${{ github.ref_name }}
          echo "✅ Changes pushed successfully"
        else
          echo "ℹ️ No changes to commit"
        fi
    
    - name: Summary
      if: always()
      run: |
        echo "## 🛒 Morrisons Scraper Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Run completed:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.results.outputs.success }}" == "true" ]; then
          echo "### ✅ Success" >> $GITHUB_STEP_SUMMARY
          echo "- **Products scraped:** ${{ steps.results.outputs.product_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** Data committed to repository" >> $GITHUB_STEP_SUMMARY
        else
          echo "### ❌ Failed" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue:** Scraping failed or no CSV generated" >> $GITHUB_STEP_SUMMARY
          echo "- **Action:** Check uploaded logs for details" >> $GITHUB_STEP_SUMMARY
        fi