name: Weekly Grocery Price Update

on:
  schedule:
    # Every Monday at 8 AM UTC (8 AM GMT winter / 9 AM BST summer)
    - cron: '0 8 * * 1'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: WebScrape/requirements.txt
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget curl unzip xvfb
    
    - name: Setup Chrome and ChromeDriver
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
    
    - name: Verify Chrome installation
      run: |
        google-chrome --version
        which google-chrome
        
        # Download and setup ChromeDriver
        CHROME_VERSION=$(google-chrome --version | sed 's/Google Chrome //' | cut -d. -f1)
        echo "Chrome major version: $CHROME_VERSION"
        
        # Get compatible ChromeDriver version
        if [ "$CHROME_VERSION" -ge "115" ]; then
          # For Chrome 115+, use the new ChromeDriver API
          CHROMEDRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_STABLE")
          echo "Using ChromeDriver version: $CHROMEDRIVER_VERSION"
          wget -O /tmp/chromedriver.zip "https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROMEDRIVER_VERSION}/linux64/chromedriver-linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /tmp/
          sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/
        else
          # For older Chrome versions
          CHROMEDRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}")
          echo "Using ChromeDriver version: $CHROMEDRIVER_VERSION"
          wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /usr/local/bin/
        fi
        
        sudo chmod +x /usr/local/bin/chromedriver
        chromedriver --version
    
    - name: Install Python dependencies
      run: |
        cd WebScrape
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Update scraper configurations for headless mode
      run: |
        cd WebScrape
        
        # Create a patch script to ensure all scrapers run in headless mode
        cat > patch_scrapers.py << 'EOF'
        import os
        import re

        def patch_file(filename):
            if not os.path.exists(filename):
                print(f"File {filename} not found, skipping...")
                return
                
            with open(filename, 'r') as f:
                content = f.read()
            
            # Add headless options if not present
            patterns_to_add = [
                "options.add_argument('--headless')",
                "options.add_argument('--no-sandbox')",
                "options.add_argument('--disable-dev-shm-usage')",
                "options.add_argument('--disable-gpu')",
                "options.add_argument('--window-size=1920,1080')",
                "options.add_argument('--disable-extensions')"
            ]
            
            # Find where options are being set
            if 'ChromeOptions()' in content or 'webdriver.ChromeOptions()' in content:
                for pattern in patterns_to_add:
                    if pattern not in content:
                        # Add after ChromeOptions() initialization
                        content = re.sub(
                            r'(options\s*=\s*.*ChromeOptions\(\))',
                            r'\1\n    ' + pattern,
                            content
                        )
            
            with open(filename, 'w') as f:
                f.write(content)
            print(f"Patched {filename}")

        # Patch all Python scraper files
        scrapers = ['aldi.py', 'asda.py', 'tesco.py', 'sainsburys.py', 'morrisons.py']
        for scraper in scrapers:
            patch_file(scraper)
        EOF
        
        python patch_scrapers.py
    
    - name: Run ALDI scraper
      timeout-minutes: 30
      run: |
        cd WebScrape
        echo "ðŸ›’ Starting ALDI scraper..."
        xvfb-run -a python aldi.py 2>&1 | tee aldi.log || echo "ALDI scraper completed with issues"
        
        if [ -f "aldi.csv" ]; then
          cp aldi.csv ../app/public/aldi.csv 2>/dev/null || mkdir -p ../app/public && cp aldi.csv ../app/public/aldi.csv
          echo "âœ… ALDI CSV updated ($(wc -l < aldi.csv) lines)"
        else
          echo "âŒ ALDI CSV not generated"
        fi
    
    - name: Run Tesco scraper
      timeout-minutes: 30
      run: |
        cd WebScrape
        echo "ðŸ›’ Starting Tesco scraper..."
        xvfb-run -a python tesco.py 2>&1 | tee tesco.log || echo "Tesco scraper completed with issues"
        
        if [ -f "tesco.csv" ]; then
          cp tesco.csv ../app/public/tesco.csv 2>/dev/null || mkdir -p ../app/public && cp tesco.csv ../app/public/tesco.csv
          echo "âœ… Tesco CSV updated ($(wc -l < tesco.csv) lines)"
        else
          echo "âŒ Tesco CSV not generated"
        fi
    
    - name: Run Sainsbury's scraper
      timeout-minutes: 40
      run: |
        cd WebScrape
        echo "ðŸ›’ Starting Sainsbury's scraper..."
        xvfb-run -a python sainsburys.py 2>&1 | tee sainsburys.log || echo "Sainsbury's scraper completed with issues"
        
        if [ -f "sainsburys.csv" ]; then
          cp sainsburys.csv ../app/public/sainsburys.csv 2>/dev/null || mkdir -p ../app/public && cp sainsburys.csv ../app/public/sainsburys.csv
          echo "âœ… Sainsbury's CSV updated ($(wc -l < sainsburys.csv) lines)"
        else
          echo "âŒ Sainsbury's CSV not generated"
        fi
    
    - name: Run Morrisons scraper
      timeout-minutes: 30
      run: |
        cd WebScrape
        echo "ðŸ›’ Starting Morrisons scraper..."
        xvfb-run -a python morrisons.py 2>&1 | tee morrisons.log || echo "Morrisons scraper completed with issues"
        
        if [ -f "morrisons.csv" ]; then
          cp morrisons.csv ../app/public/morrisons.csv 2>/dev/null || mkdir -p ../app/public && cp morrisons.csv ../app/public/morrisons.csv
          echo "âœ… Morrisons CSV updated ($(wc -l < morrisons.csv) lines)"
        else
          echo "âŒ Morrisons CSV not generated"
        fi
    
    - name: Run ASDA scraper
      timeout-minutes: 45
      run: |
        cd WebScrape
        echo "ðŸ›’ Starting ASDA scraper..."
        xvfb-run -a python asda.py 2>&1 | tee asda.log || echo "ASDA scraper completed with issues"
        
        if [ -f "asda.csv" ]; then
          cp asda.csv ../app/public/asda.csv 2>/dev/null || mkdir -p ../app/public && cp asda.csv ../app/public/asda.csv
          echo "âœ… ASDA CSV updated ($(wc -l < asda.csv) lines)"
        else
          echo "âŒ ASDA CSV not generated"
        fi
    
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs
        path: WebScrape/*.log
        retention-days: 7
    
    - name: Check for changes and prepare commit
      id: check_changes
      run: |
        mkdir -p app/public
        git add app/public/*.csv || echo "No CSV files to add"
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
          echo "changes=false" >> $GITHUB_OUTPUT
        else
          echo "Changes detected"
          echo "changes=true" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Updated files:"
          git diff --staged --name-only
          
          echo "ðŸ“ˆ CSV file info:"
          for csv in app/public/*.csv; do
            if [ -f "$csv" ]; then
              lines=$(wc -l < "$csv")
              size=$(ls -lh "$csv" | awk '{print $5}')
              echo "  $(basename $csv): $lines lines, $size"
            fi
          done
        fi
    
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
        COMMIT_MSG="ðŸ¤– Weekly grocery price update - $TIMESTAMP"
        
        git commit -m "$COMMIT_MSG"
        git push
        
        echo "âœ… Changes committed and pushed successfully"
    
    - name: Create workflow summary
      if: always()
      run: |
        echo "## ðŸ›’ Weekly Grocery Price Update Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Scraping Results:" >> $GITHUB_STEP_SUMMARY
        
        cd WebScrape
        for scraper in aldi tesco sainsburys morrisons asda; do
          if [ -f "${scraper}.csv" ]; then
            lines=$(wc -l < "${scraper}.csv")
            echo "- âœ… **${scraper^}**: $lines products scraped" >> $GITHUB_STEP_SUMMARY
          elif [ -f "../app/public/${scraper}.csv" ]; then
            lines=$(wc -l < "../app/public/${scraper}.csv")
            echo "- âœ… **${scraper^}**: $lines products (existing file)" >> $GITHUB_STEP_SUMMARY
          else
            echo "- âŒ **${scraper^}**: Failed to scrape" >> $GITHUB_STEP_SUMMARY
          fi
        done
        
        if [ "${{ steps.check_changes.outputs.changes }}" == "true" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŽ‰ **Result**: Price data updated and committed!" >> $GITHUB_STEP_SUMMARY
        else
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "â„¹ï¸ **Result**: No new data to commit." >> $GITHUB_STEP_SUMMARY
        fi
