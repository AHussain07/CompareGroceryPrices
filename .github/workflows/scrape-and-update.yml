name: Grocery Price Scraper - ALDI & Sainsburys

on:
  workflow_dispatch:
  schedule:
    - cron: '0 8 * * 1'

permissions:
  contents: write

jobs:
  scrape-groceries:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget curl unzip xvfb
    
    - name: Install Chrome
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
    
    - name: Install ChromeDriver
      run: |
        CHROME_VERSION=$(google-chrome --version | sed 's/Google Chrome //' | cut -d'.' -f1)
        
        if [ "$CHROME_VERSION" -ge "115" ]; then
          LATEST_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_STABLE")
          wget -O /tmp/chromedriver.zip "https://storage.googleapis.com/chrome-for-testing-public/$LATEST_VERSION/linux64/chromedriver-linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /tmp/
          sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
        else
          DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}")
          wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /usr/local/bin/
        fi
        
        sudo chmod +x /usr/local/bin/chromedriver
    
    - name: Install dependencies
      run: |
        cd WebScrape
        pip install -r requirements.txt
    
    - name: Fix scrapers for headless mode
      run: |
        cd WebScrape
        
        # Fix ALDI scraper
        if [ -f "aldi.py" ]; then
          sed -i 's/# options\.add_argument('\''--headless'\'')/options.add_argument('\''--headless'\'')/' aldi.py
          sed -i '/options\.add_argument('\''--headless'\'')/a options.add_argument('\''--no-sandbox'\'')' aldi.py
          sed -i '/options\.add_argument('\''--no-sandbox'\'')/a options.add_argument('\''--disable-dev-shm-usage'\'')' aldi.py
          echo "ALDI scraper patched for headless mode"
        fi
        
        # Fix Sainsburys scraper
        if [ -f "sainsburys.py" ]; then
          sed -i '/options\.add_argument('\''--disable-images'\'')/i options.add_argument('\''--headless'\'')' sainsburys.py
          sed -i 's/max_workers=[0-9]*/max_workers=1/' sainsburys.py
          echo "Sainsburys scraper patched for headless mode"
        fi
    
    - name: Create public directory
      run: mkdir -p app/public
    
    - name: Run ALDI scraper
      timeout-minutes: 30
      continue-on-error: true
      run: |
        cd WebScrape
        echo "Starting ALDI scraper..."
        xvfb-run -a -s "-screen 0 1920x1080x24" python aldi.py > aldi.log 2>&1
        
        if [ -f "aldi.csv" ]; then
          cp aldi.csv ../app/public/
          echo "ALDI completed successfully"
        else
          echo "ALDI failed"
        fi
    
    - name: Run Sainsbury's scraper
      timeout-minutes: 60
      continue-on-error: true
      run: |
        cd WebScrape
        echo "Starting Sainsbury's scraper..."
        xvfb-run -a -s "-screen 0 1920x1080x24" python sainsburys.py > sainsburys.log 2>&1
        
        if [ -f "sainsburys.csv" ]; then
          cp sainsburys.csv ../app/public/
          echo "Sainsburys completed successfully"
        else
          echo "Sainsburys failed"
        fi
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: WebScrape/*.log
        retention-days: 7
        if-no-files-found: ignore
    
    - name: Check results
      id: results
      run: |
        success_count=0
        total_products=0
        
        if [ -f "app/public/aldi.csv" ]; then
          aldi_count=$(wc -l < app/public/aldi.csv)
          total_products=$((total_products + aldi_count))
          success_count=$((success_count + 1))
          echo "ALDI: $aldi_count lines"
        fi
        
        if [ -f "app/public/sainsburys.csv" ]; then
          sainsburys_count=$(wc -l < app/public/sainsburys.csv)
          total_products=$((total_products + sainsburys_count))
          success_count=$((success_count + 1))
          echo "Sainsburys: $sainsburys_count lines"
        fi
        
        echo "success_count=$success_count" >> $GITHUB_OUTPUT
        echo "total_products=$total_products" >> $GITHUB_OUTPUT
    
    - name: Commit and push changes
      if: steps.results.outputs.success_count > '0'
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions Bot"
        
        git add -f app/public/*.csv
        
        if ! git diff --staged --quiet; then
          git commit -m "Update grocery prices - $(date -u '+%Y-%m-%d %H:%M UTC')"
          git push origin HEAD:${{ github.ref_name }}
          echo "Changes committed and pushed"
        else
          echo "No changes to commit"
        fi