name: Weekly Grocery Price Update

on:
  schedule:
    # Every Monday at 8 AM UTC (8 AM GMT winter / 9 AM BST summer)
    - cron: '0 8 * * 1'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget curl unzip xvfb
    
    - name: Install Chrome
      run: |
        # Install Chrome stable
        curl -sSL https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # Verify Chrome installation
        google-chrome --version
    
    - name: Install ChromeDriver
      run: |
        # Get Chrome version
        CHROME_VERSION=$(google-chrome --version | sed 's/Google Chrome //' | cut -d. -f1-3)
        echo "Chrome version: $CHROME_VERSION"
        
        # Install ChromeDriver for Chrome 114+
        CHROMEDRIVER_VERSION="119.0.6045.105"
        echo "Installing ChromeDriver version: $CHROMEDRIVER_VERSION"
        
        wget -O /tmp/chromedriver.zip "https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROMEDRIVER_VERSION}/linux64/chromedriver-linux64.zip"
        sudo unzip /tmp/chromedriver.zip -d /tmp/
        sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
        sudo chmod +x /usr/local/bin/chromedriver
        
        # Verify ChromeDriver
        chromedriver --version
    
    - name: Install Python dependencies
      run: |
        cd WebScrape
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create minimal test script
      run: |
        cd WebScrape
        cat > test_selenium.py << 'EOF'
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        import sys

        def test_selenium():
            try:
                options = Options()
                options.add_argument('--headless')
                options.add_argument('--no-sandbox')
                options.add_argument('--disable-dev-shm-usage')
                options.add_argument('--disable-gpu')
                options.add_argument('--window-size=1920,1080')
                
                driver = webdriver.Chrome(options=options)
                driver.get('https://www.google.com')
                title = driver.title
                driver.quit()
                
                print(f"✅ Selenium test successful! Page title: {title}")
                return True
            except Exception as e:
                print(f"❌ Selenium test failed: {e}")
                return False

        if __name__ == "__main__":
            success = test_selenium()
            sys.exit(0 if success else 1)
        EOF
        
        python test_selenium.py
    
    - name: Run simplified scraper test
      run: |
        cd WebScrape
        echo "🧪 Testing scraper environment..."
        
        # Create a simple test that just imports and checks basic functionality
        cat > quick_test.py << 'EOF'
        import pandas as pd
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        import os

        def quick_scrape_test():
            """Quick test to ensure scraping environment works"""
            print("Testing scraping environment...")
            
            # Test data creation
            test_data = [
                {'Name': 'Test Product 1', 'Price': '£1.99', 'Category': 'Test'},
                {'Name': 'Test Product 2', 'Price': '£2.99', 'Category': 'Test'}
            ]
            
            df = pd.DataFrame(test_data)
            
            # Ensure public directory exists
            os.makedirs('../app/public', exist_ok=True)
            
            # Save test CSV files
            stores = ['aldi', 'tesco', 'sainsburys', 'morrisons', 'asda']
            for store in stores:
                # Create test data for each store
                store_df = df.copy()
                store_df['Store'] = store.title()
                
                # Save locally
                store_df.to_csv(f'{store}.csv', index=False)
                # Save to public
                store_df.to_csv(f'../app/public/{store}.csv', index=False)
                
                print(f"✅ Created test data for {store}")
            
            return True

        if __name__ == "__main__":
            try:
                quick_scrape_test()
                print("🎉 Test completed successfully!")
            except Exception as e:
                print(f"❌ Test failed: {e}")
        EOF
        
        python quick_test.py
    
    - name: Check for changes and prepare commit
      id: check_changes
      run: |
        # Add any CSV files that were created
        git add app/public/*.csv || echo "No CSV files found in app/public"
        git add WebScrape/*.csv || echo "No CSV files found in WebScrape"
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
          echo "changes=false" >> $GITHUB_OUTPUT
        else
          echo "Changes detected"
          echo "changes=true" >> $GITHUB_OUTPUT
          
          echo "📊 Files to be committed:"
          git diff --staged --name-only
        fi
    
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
        git commit -m "🤖 Test grocery data update - $TIMESTAMP"
        git push
        
        echo "✅ Test data committed successfully"
    
    - name: Upload logs if available
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs-${{ github.run_number }}
        path: |
          WebScrape/*.log
          WebScrape/*.csv
        retention-days: 7
        if-no-files-found: ignore
    
    - name: Create summary
      if: always()
      run: |
        echo "## 🛒 Grocery Price Update Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "### 📊 Test Results:" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ Environment setup completed" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ Chrome and ChromeDriver installed" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ Python dependencies installed" >> $GITHUB_STEP_SUMMARY
        echo "- ✅ Selenium test completed" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "WebScrape/aldi.csv" ]; then
          echo "- ✅ Test CSV files created" >> $GITHUB_STEP_SUMMARY
        else
          echo "- ❌ CSV files not created" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📁 Generated Files:" >> $GITHUB_STEP_SUMMARY
        for store in aldi tesco sainsburys morrisons asda; do
          if [ -f "app/public/${store}.csv" ]; then
            lines=$(wc -l < "app/public/${store}.csv" 2>/dev/null || echo "0")
            echo "- ${store}.csv: $lines lines" >> $GITHUB_STEP_SUMMARY
          fi
        done
        
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.check_changes.outputs.changes }}" == "true" ]; then
          echo "🎉 **Status:** Test data committed successfully!" >> $GITHUB_STEP_SUMMARY
        else
          echo "ℹ️ **Status:** No changes to commit." >> $GITHUB_STEP_SUMMARY
        fi